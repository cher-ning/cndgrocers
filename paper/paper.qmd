---
title: "Impacts of Month, Grocery Vendor, Presale Prices, and Average Historical Pricing on Discounted Egg Dozen Prices"
subtitle: "Cheapest Discounted Prices Are Offered by T&T and in April, by Multiple Linear Regression"
author: Cher Ning-Li
thanks: "Code and data are available at: [https://github.com/cher-ning/cndgrocers](https://github.com/cher-ning/cndgrocers)."
date: today
date-format: long
abstract: "This study aims to understand the impacts of month, vendor, presale price, and average historical item pricing on the current discounted price of egg dozens using data of sales held between March and November 2024 by the 8 major grocery vendors of Canada. Using a multiple linear regression model, these factors were found to have significant interactions with the discounted price of eggs, with T&T and April observing the lowest prices within each of their own categories. These findings are key to understanding pricing patterns of different vendors across different months, helping consumers and retailers make better informed decisions."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(tidyverse)
library(arrow)
library(here)
library(ggplot2)
library(knitr)
library(kableExtra)
library(jtools)

# Read in analysis_data
analysis_data <- read_parquet(file = here("data/02-analysis_data/analysis_data.parquet"), show_col_types = FALSE)

# Read in models
model <- readRDS(file = here("models/lm_model1.rds"))
```


# Introduction

In Toronto, a city that has an absurdly high cost of living at $1,492.10 per single person even without rent included, any area where unnecessary spending can be avoided would be greatly advantageous to know [@numbeo]. For those who are trying to save as much as they can, grocery shopping and home cooking is often a strategy employed to avoid the additional expenses of eating out. Even for people don't cook often, grocery shopping is still a monthly expense that is nearly unavoidable. Within these items, eggs are a staple grocery item that is consumed often by a wide demographic of people, with the average Canadian consuming up to 242 eggs per year [@eggfacts]. It is a cheaper source of protein than meats and a common ingredient in many dishes, making it one of the most frequently purchased grocery items.

In addition, egg production is also an important industry in Canada, with 2021's production alone totaling up to a value of $1.8 billion [@eggstats]. The pay that egg farmers receive also depends on the value of eggs on the market, with British Columbian producers in 2021 receiving the highest price of \$2.41 per dozen on average [@eggstats].

Evidently, the price of eggs impacts the lives of a huge number of people, whether it be all the consumers who are purchasing eggs regularly, or the farmers who make their living by selling this product. Between these two parties is the vendors, who determine the price at which these staple food items are sold to customers for. Therefore, it would be beneficial to understand the underlying factors that determine egg pricing at various vendors.

The estimand that is targeted within this paper's analysis is the price of a dozen eggs across the 8 top Canadian grocers: Voila, T&T, Loblaws, No Frills, Metro, Galleria, Walmart Canada, and Save-On-Foods. In addition to vendor, the other variables that will also be taken into consideration are each item's presale price, month of the sale, and average historical discount pricing of egg dozens, as measured by the average discounted price of eggs in the month prior to the current sale.

Through building a Multiple Linear Regression Model, this paper finds that all four variables had non-negligible influences on the discounted price of eggs, with a key interaction term between historical pricing and presale pricing playing a role as well. Notably, T&T and April offering the most discounted egg prices comparative to all others in their own category. As well, presale price was found to have a negative relationship with discounted price, indicating that the most expensive eggs will be discounted more, when all other variables are held constant. 

The remainder of this paper is structured as follows. @sec-data will introduce the dataset used for the analysis and the relevant variables of interest. @sec-model covers how the model was set up and its weaknesses. @sec-results displays the findings of the model, and 
@sec-discussion elaborates further on the findings to add context as well as comment on the limitations of the current model. Within the Appendix, @sec-data-cleaning details how the full dataset was cleaned before modeling, @sec-obs-data comments on the implications of using a dataset of observational data for analysis, and @sec-model-diagnostics contains detailed diagnostics for the model.

# Data {#sec-data}

## Overview

The dataset used for this paper's analysis is titled "Canadian Grocery Price Data" and was obtained from Project Hammer [@projecthammer], which compiles grocery store price listings across the 8 major Canadian Grocers—Voila, T&T, Loblaws, No Frills, Metro, Galleria, Walmart, and Save-On-Foods. The dataset contains data starting from February 28, 2024 and is updated regularly with the addition of new entries. Only the entries up until November 25, 2024 are considered within this paper.

The dataset was downloaded as two separate csv files titled `hammer-4-product.csv` and `hammer-4-raw.csv`. The `product` table includes information about specific products that are available across the different grocers, with unique product ID numbers to identify each listing at each grocer. The `raw` table includes the price and more time-specific information regarding each product's listing. The two tables were joined by matching the product IDs to create the full dataset. 

The relevant variables of interest to us are: `nowtime`, `vendor`, `current_price`, `old_price`, and `product_name`, as explained below:

- **nowtime**: Date and time of when the data was collected
- **vendor**: One of the 8 Canadian grocery vendors
- **current_price**: Price at time of extract
- **old_price**: An 'old' struck-out price, indicating the item's regular pre-sale price
- **product_name**: Product name, may include brand and/or units

For ease of analysis, these additional variables were derived:

- **month**: The month of when a data entry was collected; extracted from `nowtime`
- **prev_month_avg**: The average price of a dozen eggs across all vendors during the previous month

All entries with empty values in any of these key variables were dropped. Further details regarding the data cleaning process and a glimpse of the first 5 rows of the final cleaned dataset can be found in @sec-data-cleaning.

Under the guidance of @tellingstories, the R programming language [@citeR] was used for analysis of this dataset. The package `tidyverse` [@tidyverse] was used to simulate data and test the simulated data before analysis. Packages `tidyverse` [@tidyverse] and `arrow` [@arrow] were utilized to clean the full raw dataset,  which were then also used alongside packages `testthat` [@testthat] and `here` [@here] to test the cleaned dataset. Lastly, packages `tidyverse` [@tidyverse], `rstanarm` [@rstanarm], `arrow` [@arrow], `modelsummary` [@modelsummary], and `here` [@here] were used for exploratory data analysis before creating the final model. The packages `arrow` [@arrow], `here` [@here], `ggplot2` [@ggplot], `tidyverse` [@tidyverse], `jtools` [@jtools], `knitr` [@knitr], and `kableExtra` [@kableExtra] were used for visualizing the dataset and model results below.

## Measurement

The observations in the dataset are scraped from the grocer's official website's interface, which means it only contains the information that is publicly listed and available. The recorded prices for each item are the listed price for the "in store pick up" option, with the target pickup neighbourhood being a neighbourhood in Toronto. Certain values and listings may be missed, since the internal APIs that power the grocer's websites are not accessed and specific extracts may error for certain vendors on particular days for unforeseeable reasons. Starting from July 11, the targeted variety of grocery items for data collection was greatly increased, meaning that there may be products which are missing pricing information before then.

## Variables of Interest {#sec-variables}

The outcome variable that we are interested in understanding is the `current_price`, representing the sale price of a dozen eggs. The predictor variables are `month`, `vendor`, `old_price`, and `prev_month_avg`. 

```{r}
#| label: fig-vendorprices
#| fig-cap: Average Sale Price of a Dozen Eggs Across Vendors
#| echo: false
#| warning: false
#| message: false

analysis_data |> 
  ggplot(aes(x = vendor, y = current_price)) +
  geom_boxplot(outlier.colour="black", outlier.shape=16,
             outlier.size=2, notch=FALSE) +
  theme_classic() +
  labs(x = "Vendor",
       y = "Sale Price of a Dozen Eggs")
```

@fig-vendorprices shows the summarized sale pricing of a dozen eggs across the 8 vendors. From this graph, we can observe that T&T has the lowest prices overall and Save On Foods the highest. There are also differences in the range of prices offered, with T&T and Metro having much wider price ranges compared to Galleria and Save On Foods, which have highly consistent sale pricing. 


\newpage

```{r}
#| label: fig-vendorsales
#| fig-cap: Number of Discounts Provided By Each Vendor On Eggs Between March and November 2024
#| echo: false
#| warning: false
#| message: false

analysis_data |> 
  ggplot(aes(x = vendor)) +
  geom_bar() +
  theme_classic() +
  labs(x = "Vendor",
       y = "Number of Sales")
```

@fig-vendorsales shows the number of sales provided on egg dozens, showing a large variation between vendors. Metro notably had the most egg discounts, and Galleria the least. 


\newpage

```{r}
#| label: fig-monthprices
#| fig-cap: Average Sale Price of a Dozen Eggs Across Months March to November
#| echo: false
#| warning: false
#| message: false

price_permonth <- analysis_data %>% 
  select(-prev_month_avg) %>%
  group_by(month) %>%
  summarize(avg_price = mean(current_price, na.rm = TRUE))

price_permonth <- price_permonth %>%
  mutate(month = recode(month,
                        Mar = 3,
                        Apr = 4,
                        May = 5,
                        Jun = 6,
                        Jul = 7,
                        Aug = 8, 
                        Sep = 9,
                        Oct = 10,
                        Nov = 11))

#locks in months in chronological order
price_permonth <- price_permonth[order(price_permonth$month, decreasing = FALSE),]


#converts back to month name while keeping order
price_permonth$month <- month.abb[price_permonth$month]
price_permonth$month <- factor(price_permonth$month, levels = price_permonth$month)

price_permonth |> 
  ggplot(mapping = aes(x = month, y = avg_price)) +
  geom_col() + 
  theme_classic() +
  labs(x = "Month",
       y = "Average Sale Price of a Dozen Eggs")
```

Next, @fig-monthprices shows the average sale price of a dozen eggs across different months. It can be observed that price dips slightly during the summer, reaching its lowest in July, before increasing again. Differences throughout months are typically gradual and do not fluctuate very much. 

\newpage

```{r}
#| label: fig-monthsales
#| fig-cap: Number of Discounts Provided Each Month Between March and November 2024
#| echo: false
#| warning: false
#| message: false



month_sales <- analysis_data |> count(month)
month_sales <- month_sales %>%
  mutate(month = recode(month,
                        Mar = 3,
                        Apr = 4,
                        May = 5,
                        Jun = 6,
                        Jul = 7,
                        Aug = 8, 
                        Sep = 9,
                        Oct = 10,
                        Nov = 11))

month_sales <- month_sales[order(month_sales$month, decreasing = FALSE),]
month_sales$month <- month.abb[month_sales$month]
month_sales$month <- factor(month_sales$month, levels = month_sales$month)

month_sales |> 
  ggplot(mapping = aes(x = month, y = n)) +
  geom_col() + 
  theme_classic() +
  labs(x = "Month",
       y = "Number of Sales")
```

@fig-monthsales shows the number of sales provided on egg dozens across the months, with the least number of sales occurring in July and most in November.


\newpage

```{r}
#| label: fig-oldvsnew
#| fig-cap: Presale and Sale Prices of a Dozen Eggs
#| echo: false
#| warning: false
#| message: false

analysis_data |> 
  ggplot(aes(x = old_price, y = current_price)) +
  geom_jitter(alpha = 0.3) + 
  geom_smooth(method = lm, se = FALSE) +
  geom_abline(intercept = 0, slope = 1, show.legend = TRUE, linetype = "dashed") +
  theme_classic() +
  labs(x = "Presale Price",
       y = "Sale Price") 

```

@fig-oldvsnew shows the positive and relatively linear relationship between the original presale price and discounted price of a dozen eggs across all 8 vendors. The dotted line has a slope of 1 and indicates how prices would look if discounted prices are equal to presale prices. All data points are on or below the dotted line, indicating that discounted prices are always equal to or less than the original presale price. The blue line, representing the line of best fit, has a positive but smaller slope than the dotted line, indicating that sale prices increase at a slower rate than presale prices. In other words, the greater an item's presale price, the greater the price difference would be. This confirms our intuitions about how sale events occur in the real world, as sales are typically calculated as a percentage of the original price. 


\newpage

```{r}
#| label: fig-prevmonth
#| fig-cap: Sale Price of a Dozen Eggs vs Previous Month's Average Price
#| echo: false
#| warning: false
#| message: false


analysis_data |> 
  ggplot(aes(x = prev_month_avg, y = current_price)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth(method = lm, se = FALSE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  theme_classic() +
  labs(x = "Previous Month's Average Price of a Dozen Eggs",
       y = "Sale Price") 

```

@fig-prevmonth shows the relationship between the current sale price of a dozen eggs compared to the previous month's average price. Similar to @fig-oldvsnew, the dotted line has a slope of 1 and indicates variables growing at an equal rate whereas the blue line represents the line of best fit. Here, in contrast to @fig-oldvsnew, the relationship appears much weaker with a greater scatter and deviation of values. The line of best fit has a positive slope that is less than 1, indicating that current sale prices increase when previous month's prices do, but at a slower rate. That is, a higher price average in the previous month is correlated with higher prices in the current month, but not to a high degree.

## Other Datasets

There are other food pricing related datasets available for use, such as Statistics Canada's "Average Retail Food Prices" [@otherdataset]. Though it does also contain average price information for a dozen eggs, this dataset was not utilized within this paper's analysis in the end because it only contains monthly averages that are also not divided by vendor. As well, the averages in this dataset are generalized across the entire provinces, in contrast to Project Hammer's dataset which is centred on Toronto prices [@projecthammer]. This could introduce inaccuracies into our model, as the wider geographical range may be failing to capture Toronto's comparatively higher cost of living, compared to other Ontario regions. 

# Model {#sec-model}

### Model Set-Up {#sec-model-setup}

The goal of our modeling is to understand how the predictor variables—month, vendor, presale price, and previous month's average sale price—affects the response variable of current price. For this paper, a multiple linear regression model will be utilized.

We define $Y_i$ as the current price, and initialize the full model as: 

$$
Y_i = \beta_0 + \beta_1 month + \beta_2 vendor + \beta_3 old\_price * prev\_month\_avg
$$

We create the model in R [@citeR], with help from package `tidyverse` [@tidyverse]. Model results are displayed with help from package `jtools` [@jtools].

### Model Weaknesses {#sec-model-weakness}

The first weakness of this model is that it assumes a linear relationship between the discounted price and the list of predictor variables. This oversimplification could be missing many aspects of their true relationship if it is nonlinear. As well, there could be real-world events such as economic changes or policy changes which could have significant impact on pricing, but this model would fail to capture these influences. 

Additionally, due to the targeting of dozen egg items within this analysis, it has also caused our dataset to be quite small with less than two thousand data points. Though this decision to focus in on one type of item helps narrow down the scope of analysis and increase the generalizability of findings, the small dataset size may simultaneously have the opposite effect in decreasing accuracy. 

Another weakness is that the dataset does not include information for every month of the year. Due to the lack of entries in February, there is also no values to calculate a `prev_month_avg` value for all March listings. This impacts the accuracy of our model because there could be patterns present in the winter months that would not be observable here. 

This model also treats all egg dozens as equivalent, without consideration for other qualities within the item type such as whether it is organic, white or brown eggs, egg size, and brand. Different patterns could be present when these further distinctions are also separated out into their own categories.

Lastly, this dataset is only observational data, and therefore it is insufficient to conclude causality from our current analysis. More details regarding the impact and context of this assumption can be found in @sec-obs-data.

Diagnostics that show the model's weaknesses can be found in @sec-model-diagnostics. 

\newpage

# Results {#sec-results}

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Multiple Linear Regression Model of Discounted Egg Prices Based on Vendor, Month, Presale Price, and Previous Month's Average Discounted Price"
#| warning: false

summ(model)
```

The results of this model, summarized in @tbl-modelresults, indicates that discounted price is a complex value that is impacted by a variety of factors. Because `vendor` and `month` are both categorical variables, default baseline values for them were chosen to be April and Galleria, whose effects on price would be described by the intercept value. Note that within this model, 125 entries were removed due to missing data—these would be the March entries, since they have empty values under the `prev_month_avg` variable.

For the continuous variable `old_price`, we observe a negative coefficient of $-0.80$, indicating that when all other variables are held constant, a greater presale price is correlated with a decrease in current discounted price. Intuitions behind why this value may be negative will be discussed in @sec-discussion.

The interaction term of `old_price` with `prev_month_avg` has a slight positive coefficient, meaning that when either of these characteristics increase, current discounted price is projected to increase as well. 

The $R^2$ and Adjusted $R^2$ values of 0.82 indicate that 82% of the variability in the discounted price within this dataset can be explained by the current model, which is strong evidence that these chosen variables do have influence on the estimand.


\newpage

```{r}
#| echo: false
#| eval: true
#| label: fig-vendors-result
#| fig-cap: "Coefficients Representing Each of the 8 Vendors' Impact on Discounted Price"
#| warning: false

coeff <- c(0.02, 0, -0.51, -0.54, -0.72, -0.97, -1.78, -1.87)
vendors <- c("Save On Foods", "Galleria", "Walmart", "Voila", "Loblaws", "Metro", "No Frills", "T&T")

vendor_results <- data.frame(Vendors = vendors, Coefficients = coeff)
vendor_results |>
  ggplot(mapping = aes(x = Vendors, y = Coefficients)) +
  geom_col() +
  geom_text(aes(label = Coefficients, vjust = -0.5)) + 
  theme_classic() +
  labs(x = "Vendors", 
       y = "Coefficients by Multiple Linear Regression")
```

First, we compare the vendor categories in more detail in @fig-vendors-result. Variable `vendorTandT` has the lowest coefficient value at $-1.87$, meaning that the average discounted price at T&T is expected to be the lowest, compared to other vendors. `vendorSaveOnFoods` has the highest coefficient at $0.02$, is it also the only positive coefficient for the vendors, meaning that average discounted prices at Save On Foods are expected to be the highest, and the only vendor which has higher average prices than the baseline category of Galleria.


\newpage

```{r}
#| echo: false
#| eval: true
#| label: fig-monthresults
#| fig-cap: "Coefficients Representing Each Month's Impact on Discounted Price From April to November"
#| warning: false

coeff <- c(0, 0.36, 0.83, 1.03, 1.72, 0.31, 1.13, 0.58)
months <- c("April", "May", "June", "July", "August", "September", "October", "November")
month_results <- data.frame(Months = months, Coefficients = coeff)
month_results$Months <- factor(month_results$Months, levels = month_results$Months)


month_results |>
  ggplot(mapping = aes(x = Months, y = Coefficients)) +
  geom_col() +
  geom_text(aes(label = Coefficients, vjust = -0.5)) + 
  theme_classic() +
  labs(x = "Months", 
       y = "Coefficients by Multiple Linear Regression")
```

Similarly, we can compare the coefficients within the `month` category, as shown in @fig-monthresults. Interestingly, in contrast to the overview shown in @fig-monthprices, July is no longer the month with the lowest prices. Instead, the baseline level of April is associated with the lowest prices, since all other months observe positive coefficients. This discrepancy will be discussed further in @sec-influencing-factors. The month with the highest prices by this model is August, with a coefficient of $1.72$.

# Discussion {#sec-discussion}

## Main Findings and Implications {#sec-influencing-factors}

The multiple linear regression model built in this paper investigates the influences of month, vendor, presale pricing, and average discounted price of the previous month on current egg item discounts. This model is helpful in isolating out the effects of each variable on price. In the vendor category, the effects of each vendor translates quite directly into the average listed discount price, with T&T and No Frills having the lowest coefficients as well as average prices (@fig-vendorprices; @fig-vendors-result). With these results, it can concluded that when considered alone, the vendors where customers can go to find the lowest to highest discounted egg prices would be T&T, No Frills, Metro, Loblaws, Voila, Walmart, Galleria, and Save On Foods, in that order.

More interestingly, as shown in @fig-monthprices in @sec-variables, July appeared to be the month where lowest discounted prices are offered. However, @fig-monthresults show that after isolating out the effects of other variables, it is actually the month of April that contributes most to discounting prices compared to other months. This discrepancy points to other confounding factors at play that caused the July average prices to be lowest. Further investigation with consideration for possible alternate causes would be needed to understand this pattern better. In contrast to the patterns observed in the simple data overview shown previously (@fig-monthprices), the model results now indicate that when considered individually, the months associated with the lowest to highest discounted egg prices would be April, September, May, November, June, July, October, August, in that order.

When translating these findings to decisions in the real world, it is important to keep in mind that, as shown in @fig-vendorsales, there is a large variation in number of discounted items across the different vendors. For example, though Metro is not the vendor associated with the lowest discounted price, it is the vendor that offers the greatest number of available discounted eggs. Combined with its non-negligible impact on pricing reported by the model in @tbl-modelresults, Metro may be a better overall choice than T&T and No Frills, who have the leading impacts on pricing, but offer discounts at much smaller frequency. This indicates that T&T and No Frills have discounts rarely, but when they do, the sale price is very low. On the other hand, Metro has very frequent sales, but the amount discounted is not very high.

The combination of frequency of sales with the discounted amount when considering how much benefit is actually provided to customers is a key consideration. A vendor that constantly advertises items to be "On Sale" may appear to be a good choice, but if the listed price is barely different from the original or average pricing, then this would be simply a marketing technique used by the vendor to disguise their regular price to appeal to customers without losing out on profit. This is a directly worthy of future investigation. 

Frequency of sales occurring is also an important consideration because it impacts the accuracy of the model in predicting prices of eggs sold at that chain. That is, the observation that Galleria has very few sale events also has the effect that the model's accuracy when applied to Galleria listings will potentially be lower than when applied to Metro, which has a much higher number of discounts within this dataset.

The variable `old_price`, representing an item's presale price, was found to have a negative coefficient at $-0.80$. This may be surprising at first because one would expect discounted price to increase as presale price increases. However, after taking the intercept base price into consideration, the interpretation for this coefficient makes much more sense. This result indicates that given every other variable is held constant, a greater presale price is correlated to a lower discounted price. This understanding makes much more intuitive sense, as sale events are typically calculated by percentage of the original price, meaning that a greater original price would lead to a greater decrease in price, thereby causing a greater decrease in discounted price in the end. 

## Weaknesses and Next Steps {#sec-nextsteps}

To further elaborate on the model weaknesses discussed in @sec-model-weakness, this overall study can greatly improved by combining other relevant datasets into the current analysis data. The set used to create the model has a relatively small sample size of only $1,278$ and combining with another source of data to obtain more entries would greatly increase the accuracy of the resulting model. Specifically, the first priority for improvement would be to obtain data points that span the full year so that our analysis is not restricted to only March to November. There could be key patterns of discounting in the winter months that are completely unobservable with the current dataset.

As well, for next steps, it would also interesting to refine the measure of historical pricing further to distinguish by vendor in addition to month. With the current model, the measure of historical pricing is generalized to all vendors, which we also know from analysis has a significant effect on pricing. Therefore, if the historical pricing measure was even more specified, a more accurate model could be created.

Another potential direction of improving the current model could be using a completely different model type. This model violates several linear regression assumptions, as shown in @sec-model-diagnostics. Though there are fixes that could be employed to achieve a better fit even with a linear model, it may be better to use a more complex model to begin with, such as a Bayesian model. 

\newpage

\appendix

# Appendix {-}


# Additional data details 

## Data-Cleaning {#sec-data-cleaning}

After combining the two tables, `raw` and `product`, by matching each entry's product ID, the full dataset with $12,753,964$ entries was created. Then, entries with "egg" or "eggs", and "dozen" or "12" appearing in their product name or units were selected for. All February entries were omitted from analysis due to data collection starting on 28 February, 2024, which means there is a lack of sufficient data for that month to make any reliable conclusions from. 

All unannounced price changes, including increases or decreases, have only a `current_price` value and empty `old_price` values, so all such entries were filtered out to narrow down analysis onto explicitly advertised sale events only. Then, the `current_price` and `old_price` columns were filtered to ensure all values were non-negative, as these entries are evidently the result of measurement error during data scraping. 


```{r}
#| label: fig-datahead
#| fig-cap: Sample of Analysis Data
#| fig-align: center
#| echo: false
#| warning: false
#| message: false

kable(head(analysis_data, 5)) %>% 
  kable_styling(
    font_size = 10,
    latex_options = c("scale_down"),
    full_width = FALSE,
    position = "center"
  ) %>% 
  column_spec(4, width = "15em")

```

After cleaning the dataset and adding in the derived variables, the final dataset of $1,278$ entries is what analysis will be conducted on. The first 5 rows from this analysis data is shown in @fig-datahead.

## Observational Data and Sampling {#sec-obs-data}

The dataset used is a compilation of price listings collected from grocery store websites directly, meaning that it is only observational data that was compiled without conducting of an experiment. This means that caution needs to be taken when making conclusions of causation from this data, because we can only be certain of correlation unless thorough tests are conducted. Our conclusions can possibly be affected by two common misconceptions, Simpson's and Berkson's paradoxes. 

Simpson's paradox is when a subset of data presents a relationship that is different from when the full dataset is considered due to lack of consideration for a confounder variable, which is the true cause of a relationship. Berkson's paradox is when a dataset is so specifically subsetted that patterns found are different from the full dataset [@tellingstories].

Within this paper's context, both paradoxes are at risk of occurring because our analysis is conducted on the subset of only egg dozen listings. Therefore, when making conclusions, it is important to remember that the patterns of correlation between variables observed within our subset of egg prices cannot be generalized to the full dataset of all grocery store listings. For example, it is possible that though in our analysis, T&T offers the lowest discounted prices [@fig-vendorprices] for eggs, they could be offering the highest prices when averaged across all product listings. 

In the same vein, the lack of significant price change around September could also be because of our sampling for egg items. Due to the school semester starting in September, intuition tells us that there are likely many sales going on for school supplies. Therefore, if we did not limit our search to egg dozens only, it is possible that September could show the lowest average prices instead of July, as shown in @fig-monthprices.

This is one weakness inherent to using observational data, that there are many unknown or uncontrolled variables which could impact our analysis. Many errors can occur from making unsupported claims that are generalized beyond the specific subset where analysis was conducted, so care must be taken when interpreting model outcomes. 

There are also potential weaknesses introduced by each level of sampling for this analysis. First, when Project Hammer scrapes the grocer websites, there may be items that were not tracked within this dataset. Especially before July, when information on a greater variety of products started being collected, there may be many missed entries of discounts on eggs. This introduces a potential sampling bias that may impact the accuracy of the model's results. Further, due to the selection of these 8 specific vendors in Canada, there may pricing patterns at other grocery chains that are unobservable from this dataset. For example, how would family-run grocery stores compare to these large chains? Are there similarities in pricing patterns across the months, or would they exhibit completely different behaviour? 

\newpage

## Diagnostics {#sec-model-diagnostics}

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-resid-model
#| fig-cap: "Residual vs Fitted Values Plot for Model"

plot(model, which = 1)
```

@fig-resid-model shows the residuals vs fitted values for this paper's model. This plot can be used to check the linearity and independent error assumptions of Multiple Linear Regression modeling. Our result does not fully resemble a null plot, as expected under these assumptions, indicating that some non-linear transformations on the predictor variables, response variable, or some combination of both can be used to improve the fit of this model. 


\newpage

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-qqplot
#| fig-cap: "QQ-Normal Plot for Model"

plot(model, which = 2)
```

@fig-qqplot shows the QQ plot for the current model, which checks for the normal error assumption of Linear Regression modelling. As observed, the points deviate heavily from the straight line on the lower end, indicating that errors are not normally distributed.


\newpage

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-standardizedfitted
#| fig-cap: "Standardized Residuals vs Fitted Values Plot for Model"

plot(model, which = 3)
```

@fig-standardizedfitted shows the standardized residuals vs fitted values graph for this model, which can be used to check the constant variance assumption of Linear Regression modelling. Our graph shows clustering, rather than an even spread around 0 that is expected, indicating a violation of this assumption. This means that a variance-stabilizing transformation on the response variable would be required to improve model accuracy further.


\newpage

# References


